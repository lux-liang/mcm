% ========== 13. AI Usage Report ==========
\section*{AI Usage Report}
\addcontentsline{toc}{section}{AI Usage Report}

Per MCM/ICM guidelines, we provide comprehensive disclosure of artificial intelligence tool usage in this submission. Team 2602828 employed AI assistants strategically for efficiency gains while maintaining rigorous human oversight of all substantive contributions.

\subsection*{AI Tools Deployed}

\noindent\textbf{Claude 3 Opus (Anthropic)}: Employed for (1) literature review synthesis---AI summarized 15+ peer-reviewed papers on AI displacement, occupational forecasting, and skill obsolescence; all citations were subsequently verified independently against original sources; (2) mathematical notation and LaTeX equation formatting to ensure consistency and correct cross-referencing; (3) code debugging and logical error detection in the Python simulation suite; (4) draft text expansion and stylistic refinement for non-technical sections.

\noindent\textbf{GitHub Copilot}: Used for Python code autocompletion in \texttt{generate\_detailed\_flowchart.py}. The system suggested boilerplate matplotlib code and function stubs; all generated code underwent rigorous team review, parameter validation, and integration testing before deployment. No Copilot code was deployed without independent verification.

\noindent\textbf{Grammarly Premium}: Applied as a final-pass writing assistant for grammar, tone consistency, and style conformance to MCM standards. Grammarly identified comma splices and run-on sentences but made no changes to technical content, model structure, or numerical results.

\subsection*{Human Oversight and Verification}

All AI outputs passed through the following human-controlled quality gates:

\begin{enumerate}[noitemsep, leftmargin=2em]
\item \textbf{Mathematical Correctness}: Every differential equation, tipping point derivation, and sensitivity index was derived independently by team members. AI did not generate mathematical content; it only reformatted or typeset team-authored equations.
\item \textbf{Factual Accuracy}: All literature citations (O*NET taxonomy, BLS OEWS data specifications, prior occupational forecasting models) were cross-checked against authoritative sources. AI summaries served as reading aids only.
\item \textbf{Code Validation}: The Python flowchart generator was executed and tested against sample inputs; output visualizations were inspected for correctness before inclusion in the paper.
\item \textbf{Editorial Review}: Every AI-assisted section underwent substantive review by at least one team member before inclusion.
\end{enumerate}

\subsection*{Intellectual Provenance}

The core intellectual contributions are entirely original team work:

\begin{itemize}[noitemsep]
\item \textbf{Problem Formulation}: Identification of the tipping point paradox and the need for task-granular AI exposure analysis.
\item \textbf{TECM Framework}: Conception, mathematical development, and empirical calibration of all three models (Task Decomposition, Verification-Bottleneck Congestion, Educational Feedback).
\item \textbf{Institutional Analysis}: Selection of occupations, institutions, and sector-specific recommendations.
\item \textbf{Sensitivity Analysis}: Design and execution of the PRCC analysis and Monte Carlo uncertainty quantification.
\end{itemize}

AI tools served exclusively as assistive technologies for efficiency (e.g., speeding up literature digestion, formatting consistency) and error-catching (e.g., grammar and syntax). They did not drive model design, analysis strategy, or policy conclusions.

\vspace{0.2em}
\noindent\textit{Team 2602828 certifies full compliance with COMAP Artificial Intelligence Usage Disclosure Requirements and affirms that all reported data, models, and recommendations are original or properly attributed.}

\label{LastPage}

